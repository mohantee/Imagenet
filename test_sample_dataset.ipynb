{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.10"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FzFmcBENmYyH"},"source":["# üß† ResNet-50 Training on Custom 25-Class ImageNet Mini Subset\n","This Colab notebook will:\n","- üì• Download ImageNet Mini (1000 classes)\n","- ‚úÇÔ∏è Select 25 random classes\n","- üß∞ Create a new subset dataset\n","- üß† Train a ResNet-50 at 224√ó224 resolution\n","- üíæ Save the best checkpoint\n","- üß™ Evaluate accuracy"],"id":"FzFmcBENmYyH"},{"cell_type":"code","metadata":{"id":"5gkeON50mYyI"},"source":["import json, os\n","\n","# ‚úÖ Hardcoded Kaggle credentials (replace with your actual values)\n","kaggle_credentials = {\"username\":\"santosh993\",\"key\":\"24c6fc9fab794da2aeb82937d78bd5\"}\n","\n","# Write kaggle.json file\n","os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n","with open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), \"w\") as f:\n","    json.dump(kaggle_credentials, f)\n","\n","# Set permissions\n","os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)\n","!kaggle datasets list -s imagenet | head"],"id":"5gkeON50mYyI","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KoMrLQFumYyJ","executionInfo":{"status":"ok","timestamp":1760421793216,"user_tz":-330,"elapsed":828,"user":{"displayName":"Mohan","userId":"06552445326308276007"}},"outputId":"270ad0e1-a5fd-405c-df71-2a1adde9f096"},"source":["# üì• Step 1: Download ImageNet Mini (1000 classes)\n","!kaggle datasets download -d ifigotin/imagenetmini-1000\n","!unzip -q imagenetmini-1000.zip -d /content/imagenet_mini\n","!ls /content/imagenet_mini"],"id":"KoMrLQFumYyJ","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n","    out = args.func(**command_args)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n","    with self.build_kaggle_client() as kaggle:\n","         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n","    username=self.config_values['username'],\n","             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n","KeyError: 'username'\n","unzip:  cannot find or open imagenetmini-1000.zip, imagenetmini-1000.zip.zip or imagenetmini-1000.zip.ZIP.\n","ls: cannot access '/content/imagenet_mini': No such file or directory\n"]}]},{"cell_type":"code","metadata":{"id":"0C6A2m6GmYyJ"},"source":["# ‚úÇÔ∏è Step 2: Pick 25 classes\n","import os, random, shutil\n","\n","src_train = '/content/imagenet_mini/imagenet-mini/train'\n","src_val = '/content/imagenet_mini/imagenet-mini/val'\n","\n","all_classes = sorted(os.listdir(src_train))\n","print(f\"Total classes available: {len(all_classes)}\")\n","\n","selected_classes = random.sample(all_classes, 25)\n","print(\"üìä Selected classes:\", selected_classes)"],"id":"0C6A2m6GmYyJ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpOA11o5mYyJ"},"source":["# üß∞ Step 3: Copy only selected classes into new dataset folder\n","dst_train = '/content/imagenet25/train'\n","dst_val = '/content/imagenet25/val'\n","os.makedirs(dst_train, exist_ok=True)\n","os.makedirs(dst_val, exist_ok=True)\n","\n","for cls in selected_classes:\n","    shutil.copytree(os.path.join(src_train, cls), os.path.join(dst_train, cls))\n","    shutil.copytree(os.path.join(src_val, cls), os.path.join(dst_val, cls))\n","\n","print('‚úÖ 25-class subset created.')\n","!ls /content/imagenet25/train | head"],"id":"IpOA11o5mYyJ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hia_jS6XmYyJ"},"source":["# üß† Step 4: Data loaders with standard ImageNet transforms (256‚Üí224)\n","import torch\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","train_dataset = datasets.ImageFolder(dst_train, transform=transform)\n","val_dataset   = datasets.ImageFolder(dst_val, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n","test_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n","\n","num_classes = len(train_dataset.classes)\n","print(f'‚úÖ {num_classes} classes | {len(train_dataset)} train | {len(test_loader)} val')"],"id":"hia_jS6XmYyJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YJUr0HQLJPET"},"id":"YJUr0HQLJPET","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ihA7K15AJPBj"},"id":"ihA7K15AJPBj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","\n","        # 1x1 convolution for dimension reduction\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","\n","        # 3x3 convolution\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n","                              stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        # 1x1 convolution for dimension increase\n","        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n","                              kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # Shortcut connection\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels * self.expansion:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels * self.expansion,\n","                         kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels * self.expansion)\n","            )\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        out += self.shortcut(identity)\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ResNet50(nn.Module):\n","    def __init__(self, num_classes=1000):\n","        super().__init__()\n","\n","        # Initial convolution layer\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        # ResNet stages\n","        self.stage1 = self._make_stage(64, 64, 3, stride=1)      # Output: 256 channels\n","        self.stage2 = self._make_stage(256, 128, 4, stride=2)    # Output: 512 channels\n","        self.stage3 = self._make_stage(512, 256, 6, stride=2)    # Output: 1024 channels\n","        self.stage4 = self._make_stage(1024, 512, 3, stride=2)   # Output: 2048 channels\n","\n","        # Global average pooling and final fully connected layer\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(2048, num_classes)\n","\n","        # Initialize weights\n","        self._initialize_weights()\n","\n","    def _make_stage(self, in_channels, out_channels, num_blocks, stride):\n","        layers = []\n","\n","        # First block with specified stride\n","        layers.append(Bottleneck(in_channels, out_channels, stride))\n","\n","        # Remaining blocks with stride 1\n","        for _ in range(1, num_blocks):\n","            layers.append(Bottleneck(out_channels * 4, out_channels))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)    # 224x224x3 -> 112x112x64\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)  # 112x112x64 -> 56x56x64\n","\n","        x = self.stage1(x)   # 56x56x64 -> 56x56x256\n","        x = self.stage2(x)   # 56x56x256 -> 28x28x512\n","        x = self.stage3(x)   # 28x28x512 -> 14x14x1024\n","        x = self.stage4(x)   # 14x14x1024 -> 7x7x2048\n","\n","        x = self.avgpool(x)  # 7x7x2048 -> 1x1x2048\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)       # 2048 -> 1000\n","\n","        return x"],"metadata":{"id":"1HdaxvaYJO-T"},"id":"1HdaxvaYJO-T","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from tqdm import tqdm\n","import os\n","\n","\n","def train(model, train_loader, criterion, optimizer, device, epoch):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n","    for batch_idx, (inputs, targets) in enumerate(pbar):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        # Zero the gradient buffers\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Statistics\n","        running_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","        # Update progress bar\n","        pbar.set_postfix({\n","            'loss': running_loss/(batch_idx+1),\n","            'acc': 100.*correct/total\n","        })\n","\n"],"metadata":{"id":"tMftOUd7JO7b"},"id":"tMftOUd7JO7b","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from tqdm import tqdm\n","import os\n","\n","def test(model, test_loader, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, targets in tqdm(test_loader, desc='Evaluating'):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = outputs.max(1)\n","\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","    accuracy = 100. * correct / total\n","    print(f'Accuracy on test set: {accuracy:.2f}%')\n","    return accuracy\n","\n"],"metadata":{"id":"4mjqLw6PJO4b"},"id":"4mjqLw6PJO4b","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_i-Eq1hSJIR7"},"id":"_i-Eq1hSJIR7","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nUuYMKfvJepF"},"id":"nUuYMKfvJepF","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# üèãÔ∏è Step 5: Train ResNet-50\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models\n","from tqdm import tqdm\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = ResNet50()\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n"],"metadata":{"id":"3PTbED9lJel7"},"id":"3PTbED9lJel7","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UcRlzX-EJeZr"},"id":"UcRlzX-EJeZr","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MrfkWf3XmYyK"},"source":["best_val_acc = 0\n","checkpoint_path = '/content/resnet50_best_25class.pth'\n","EPOCHS = 5\n","start_epoch = 0\n","\n","if os.path.exists(checkpoint_path):\n","    print(f\"üîÅ Found existing checkpoint at {checkpoint_path}. Resuming training...\")\n","    checkpoint = torch.load(checkpoint_path, map_location=device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    if 'scheduler_state_dict' in checkpoint:\n","        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","    start_epoch = checkpoint['epoch'] + 1\n","    best_val_acc = checkpoint.get('best_val_acc', 0.0)\n","    print(f\"‚úÖ Resumed from epoch {start_epoch}, best_val_acc={best_val_acc:.4f}\")\n","else:\n","    print(\"üöÄ No checkpoint found. Starting training from scratch.\")\n","\n","# --- Training Loop ---\n","num_epochs = 300  # Example; replace with yours\n","\n","for epoch in range(start_epoch, EPOCHS):\n","    print(f\"\\nEPOCH: {epoch+1}/{EPOCHS}\")\n","\n","    # Clear memory before each epoch\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    # gc.collect()\n","\n","    # Training\n","    train(model, train_loader, criterion, optimizer, device, epoch)\n","\n","    # Testing\n","    val_acc = test(model, test_loader, device)\n","\n","\n","    # --- Save checkpoint ---\n","    state = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'best_val_acc': best_val_acc,\n","    }\n","    if 'scheduler' in locals():\n","        state['scheduler_state_dict'] = scheduler.state_dict()\n","\n","    torch.save(state, checkpoint_path)\n","    print(f\"üíæ Checkpoint saved at epoch {epoch+1}\")\n","\n","    # --- Optionally keep best model ---\n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","        torch.save(model.state_dict(), checkpoint_path)\n","        print(f\"üèÜ New best model saved (val_acc={val_acc:.2f}%)\")\n"],"id":"MrfkWf3XmYyK","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZ8jJ_ykmYyK"},"source":["# üß™ Step 6: Reload and Evaluate Checkpoint\n","# best_model = models.resnet50(weights=None)\n","# best_model.fc = nn.Linear(best_model.fc.in_features, num_classes)\n","# best_model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n","# best_model = best_model.to(device)\n","# best_model.eval()\n","\n","# val_correct, val_total = 0, 0\n","# with torch.no_grad():\n","#     for x, y in val_loader:\n","#         x, y = x.to(device), y.to(device)\n","#         out = best_model(x)\n","#         val_correct += (out.argmax(1) == y).sum().item()\n","#         val_total += y.size(0)\n","\n","# final_acc = val_correct / val_total\n","# print(f'‚úÖ Final best checkpoint accuracy: {final_acc:.4f}')"],"id":"dZ8jJ_ykmYyK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Plotting results\n","# import matplotlib.pyplot as plt\n","# fig, axs = plt.subplots(2,2,figsize=(15,10))\n","# axs[0, 0].plot([t.item() for t in train_losses])\n","# axs[0, 0].set_title(\"Training Loss\")\n","# axs[1, 0].plot(train_acc)\n","# axs[1, 0].set_title(\"Training Accuracy\")\n","# axs[0, 1].plot(test_losses)\n","# axs[0, 1].set_title(\"Test Loss\")\n","# axs[1, 1].plot(test_acc)\n","# axs[1, 1].set_title(\"Test Accuracy\")\n","# plt.show()"],"metadata":{"id":"IBtfGYSDOiqT"},"id":"IBtfGYSDOiqT","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BIX9QjVGmYyK"},"source":["# üì§ Optional: Download Checkpoint\n","from google.colab import files\n","files.download(checkpoint_path)"],"id":"BIX9QjVGmYyK","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BK6eqXV1np0e"},"id":"BK6eqXV1np0e","execution_count":null,"outputs":[]}]}